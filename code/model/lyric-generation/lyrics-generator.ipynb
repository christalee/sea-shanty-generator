{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lyrics Generation Test\n",
    "Here will test the effeciacy of our models. To see if the network learns to create more novel lyrics\n",
    "\n",
    "Each model will be fed a seed line of text to base 100 characters of prediction on.\n",
    "\n",
    "To judge the progress of the model over epoch we will test the 01, 05, 10, 15, and 20 epoch weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus Data and Dictionaries\n",
    "In order to convert the outputs from the model we will need translation dictionaries\n",
    "\n",
    "Loading in the lyrics corpus will let us create these dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rYaoX1N8ALn3",
    "outputId": "a1326695-698e-4c44-b284-99c13663ebd2"
   },
   "outputs": [],
   "source": [
    "# Loading in Shanties lyrics corpus\n",
    "shanties = open('../../../data/shanties_all.txt', encoding='utf-8').read()\n",
    "\n",
    "# Creating a list of all unique characters and variable of total number of uniques\n",
    "chars_list = sorted(list(set(shanties)))\n",
    "n_chars = len(chars_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-tUbc-2WALn1"
   },
   "outputs": [],
   "source": [
    "# Creating a dictionary to map each unique character to a number\n",
    "chars_to_ints = dict((c, i) for i, c in enumerate(chars_list))\n",
    "\n",
    "# Creating a dictionary to return numbers to characters\n",
    "ints_to_chars = dict((i, c) for  i, c in enumerate(chars_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Models\n",
    "Each model will be loaded from the model-building notebook and then loaded with the desired weights.\n",
    "\n",
    "Additionally each model will be added to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating empyt list for models\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 1\n",
    "shanty_writer1 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer1.load_weights('../model-building//model-weights/weights-improvement-01-2.3265.hdf5')\n",
    "models.append(shanty_writer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 2\n",
    "shanty_writer2 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer2.load_weights('../model-building//model-weights/weights-improvement-02-1.9675.hdf5')\n",
    "models.append(shanty_writer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 3\n",
    "shanty_writer3 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer3.load_weights('../model-building//model-weights/weights-improvement-03-1.8372.hdf5')\n",
    "models.append(shanty_writer3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 4\n",
    "shanty_writer4 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer4.load_weights('../model-building//model-weights/weights-improvement-04-1.7547.hdf5')\n",
    "models.append(shanty_writer4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 5\n",
    "shanty_writer5 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer5.load_weights('../model-building//model-weights/weights-improvement-05-1.6951.hdf5')\n",
    "models.append(shanty_writer5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 6\n",
    "shanty_writer6 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer6.load_weights('../model-building//model-weights/weights-improvement-06-1.6497.hdf5')\n",
    "models.append(shanty_writer6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 7\n",
    "shanty_writer7 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer7.load_weights('../model-building//model-weights/weights-improvement-07-1.6137.hdf5')\n",
    "models.append(shanty_writer7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 8\n",
    "shanty_writer8 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer8.load_weights('../model-building//model-weights/weights-improvement-08-1.5849.hdf5')\n",
    "models.append(shanty_writer8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 9\n",
    "shanty_writer9 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer9.load_weights('../model-building//model-weights/weights-improvement-09-1.5610.hdf5')\n",
    "models.append(shanty_writer9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 10\n",
    "shanty_writer10 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer10.load_weights('../model-building//model-weights/weights-improvement-10-1.5408.hdf5')\n",
    "models.append(shanty_writer10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 11\n",
    "shanty_writer11 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer11.load_weights('../model-building//model-weights/weights-improvement-11-1.5240.hdf5')\n",
    "models.append(shanty_writer11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 12\n",
    "shanty_writer12 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer12.load_weights('../model-building//model-weights/weights-improvement-12-1.5088.hdf5')\n",
    "models.append(shanty_writer12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 13\n",
    "shanty_writer13 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer13.load_weights('../model-building//model-weights/weights-improvement-13-1.4969.hdf5')\n",
    "models.append(shanty_writer13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 14\n",
    "shanty_writer14 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer14.load_weights('../model-building//model-weights/weights-improvement-14-1.4868.hdf5')\n",
    "models.append(shanty_writer14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 15\n",
    "shanty_writer15 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer15.load_weights('../model-building//model-weights/weights-improvement-15-1.4769.hdf5')\n",
    "models.append(shanty_writer15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 16\n",
    "shanty_writer16 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer16.load_weights('../model-building//model-weights/weights-improvement-16-1.4681.hdf5')\n",
    "models.append(shanty_writer16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 17\n",
    "shanty_writer17 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer17.load_weights('../model-building//model-weights/weights-improvement-17-1.4627.hdf5')\n",
    "models.append(shanty_writer17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 18\n",
    "shanty_writer18 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer18.load_weights('../model-building//model-weights/weights-improvement-18-1.4551.hdf5')\n",
    "models.append(shanty_writer18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 19\n",
    "shanty_writer19 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer19.load_weights('../model-building//model-weights/weights-improvement-19-1.4501.hdf5')\n",
    "models.append(shanty_writer19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 20\n",
    "shanty_writer20 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer20.load_weights('../model-building//model-weights/weights-improvement-20-1.4466.hdf5')\n",
    "models.append(shanty_writer20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outputting Function\n",
    "For testing we'll use each model as a parameter in a function that will output the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lyrics_writer(seed_string, models_list, n_predictions):\n",
    "    count = 0\n",
    "    # Converting seed string into a list of numbers\n",
    "   # seq_pattern = [chars_to_ints[char] for char in seed_string.lower()]\n",
    "    for model in models_list:\n",
    "        # Adding one to counter\n",
    "        count += 1\n",
    "        # Converting seed string into a list of numbers\n",
    "        seq_pattern = [chars_to_ints[char] for char in seed_string.lower()]\n",
    "        # Creating empty string to append results too\n",
    "        output_string = ''\n",
    "        # Each iteration in loop will predict one character\n",
    "        for i in range(n_predictions):\n",
    "            # Creating x data to predict off. Reshaping and normalizing input list\n",
    "            x = np.reshape(seq_pattern, (1, len(seq_pattern), 1))\n",
    "            x = x / float(n_chars)\n",
    "            # Creating predictions\n",
    "            preds = model.predict(x, verbose=0)\n",
    "            # Ordering predictions by most likely character\n",
    "            index = np.argmax(preds)\n",
    "            # Converting result to character\n",
    "            result = ints_to_chars[index]\n",
    "            # Reading in current pattern\n",
    "            seq_in = [ints_to_chars[value] for value in seq_pattern]\n",
    "            # Adding result to input list\n",
    "            seq_pattern.append(index)\n",
    "            # Shifting pattern over one index for next pass through loop\n",
    "            seq_pattern = seq_pattern[1:len(seq_pattern)]\n",
    "            # Appending the result seed_string to print as final output\n",
    "            output_string = output_string + result\n",
    "            \n",
    "        print()\n",
    "        print(f'Epoch {count}:')\n",
    "        print(f'{seed_string}{output_string}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Lyrics\n",
    "Each model weight will be tested with the same string. This string has to be the same number of characters as the sequence length that the model was trained on. In this case 50 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_string = 'Washington DC is the best campus of General Assemb'\n",
    "len(input_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1:\n",
      "Washington DC is the best campus of General Assembn the sail the sailor sail the sailor sail the sailor sail the sailor sail the sailor sail the sailo\n",
      "\n",
      "\n",
      "Epoch 2:\n",
      "Washington DC is the best campus of General Assembe the sailor s bootier she s a sailor s bootier the sailor s bootier she s a sailor s bootier the sa\n",
      "\n",
      "\n",
      "Epoch 3:\n",
      "Washington DC is the best campus of General Assembe the sailor s io the sailor s io the sailor s io the sailor s io the sailor s io the sailor s io th\n",
      "\n",
      "\n",
      "Epoch 4:\n",
      "Washington DC is the best campus of General Assembe the ship was a sailor s a sailor s a sailor s a sailor s a sailor s a sailor s a sailor s a sailor\n",
      "\n",
      "\n",
      "Epoch 5:\n",
      "Washington DC is the best campus of General Assembe the sailor love we ll roar and the sailor love we ll roar and the sailor love we ll roar and the s\n",
      "\n",
      "\n",
      "Epoch 6:\n",
      "Washington DC is the best campus of General Assemb the sailor s land the sailor love the sailor s land the sailor love the sailor s land the sailor lo\n",
      "\n",
      "\n",
      "Epoch 7:\n",
      "Washington DC is the best campus of General Assembe the sea and the whnds and she s a lan o come all you bold sea bott and she s in the sea and the wh\n",
      "\n",
      "\n",
      "Epoch 8:\n",
      "Washington DC is the best campus of General Assembe the sailor lad i do adore and she said the sailor lad i do adore and she said the sailor lad i do \n",
      "\n",
      "\n",
      "Epoch 9:\n",
      "Washington DC is the best campus of General Assembe on the sea and the sailor s land and the sailor s love the sea and the sailor s land and the sailo\n",
      "\n",
      "\n",
      "Epoch 10:\n",
      "Washington DC is the best campus of General Assember the sea and the sea and the sea and the sea and the sea and the sea and the sea and the sea and t\n",
      "\n",
      "\n",
      "Epoch 11:\n",
      "Washington DC is the best campus of General Assember the sailor lad and the sailor lad and the sea so sail the sea so sail the sea so sail the sea so \n",
      "\n",
      "\n",
      "Epoch 12:\n",
      "Washington DC is the best campus of General Assember the sailor lad and the sailor lad and the sailor lad and the sailor lad and the sailor lad and th\n",
      "\n",
      "\n",
      "Epoch 13:\n",
      "Washington DC is the best campus of General Assember and the sailor loves the sailor loves the sailor loves the sailor loves the sailor loves the sail\n",
      "\n",
      "\n",
      "Epoch 14:\n",
      "Washington DC is the best campus of General Assember the sailor loves the maiden oh the boats of the boats and she sailed away the sailor loves the ma\n",
      "\n",
      "\n",
      "Epoch 15:\n",
      "Washington DC is the best campus of General Assember and the sea and the sailors when i was a sailor s land we ll sant and we ll roar like true you an\n",
      "\n",
      "\n",
      "Epoch 16:\n",
      "Washington DC is the best campus of General Assember the sailor loves the sailor loves the bottle oh the sailor loves the bottle oh the sailor loves t\n",
      "\n",
      "\n",
      "Epoch 17:\n",
      "Washington DC is the best campus of General Assember and the storm and the storm and the storm and the storm and the storm and the storm and the storm\n",
      "\n",
      "\n",
      "Epoch 18:\n",
      "Washington DC is the best campus of General Assember the sailor s streat and street and the sea and the sea and the sea and the sea and the sea and th\n",
      "\n",
      "\n",
      "Epoch 19:\n",
      "Washington DC is the best campus of General Assember and the ship s a cantain she s a health to the ship s a cantain she s a health to the ship s a ca\n",
      "\n",
      "\n",
      "Epoch 20:\n",
      "Washington DC is the best campus of General Assember the sailor loves the sea and the ship the sailor loves the sea and the ship the sailor loves the \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Writing lyrics for all 20 epochs\n",
    "lyrics_writer(input_string, models, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Results\n",
    "We can see several noticeable things about the lyrics written:\n",
    "\n",
    "**Epoch 1**\n",
    "- Even from the first epoch we see fully spelled words\n",
    "- The first character result for \"Assemb\" is \"n\". This doesn't make much grammatical sense.\n",
    "\n",
    "**Epochs 2 - 4**\n",
    "- The model begins to come up with novel words such as \"bootier\"\n",
    "- Has replaced the \"n\" on \"Assemb\" with an \"e\".\n",
    "\n",
    "**Epochs 5 - 9**\n",
    "- Epoch 6 drops the \"e\" from \"Assemb\" but it returns with the later epochs\n",
    "- We see a bit more variety in terms of words but \"sailor\" is still very prevalent\n",
    "\n",
    "**Epochs 10 - 19**\n",
    "- \"Assembe\" is now \"Assember\". While still a nonsense word it makes some lyrical sense.\n",
    "- While the pattern of words is still generally short we see a bit more variety in word choice by epoch\n",
    "\n",
    "**Epoch 20**\n",
    "- The final epoch has less variety but seems to make the most sense as a single lyrics\n",
    " - \"the sailor loves the sea and the ship\"\n",
    "\n",
    "Over all the model created what could be interpreted as lyrics for a line for a song.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "It seems the model may have been over fit as every output was a repetition of a few words.\n",
    "\n",
    "To minimize repetition we will try to following\n",
    "- Run the same model but with different sequence and step lengths\n",
    "- Run a less performant model with variable sequence and step lengths\n",
    "- Process the corpus differently:\n",
    " - Analyze the document by words rather then characters\n",
    " - One hot encoding\n",
    "- Research alternate ways bring in variability into text prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi] *",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
