{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lyrics Generation Test\n",
    "Here will test the effeciacy of our models. To see if the network learns to create more novel lyrics\n",
    "\n",
    "Each model will be fed a seed line of text to base 100 characters of prediction on.\n",
    "\n",
    "To judge the progress of the model over epoch we will test the 01, 05, 10, 15, and 20 epoch weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus Data and Dictionaries\n",
    "In order to convert the outputs from the model we will need translation dictionaries\n",
    "\n",
    "Loading in the lyrics corpus will let us create these dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rYaoX1N8ALn3",
    "outputId": "a1326695-698e-4c44-b284-99c13663ebd2"
   },
   "outputs": [],
   "source": [
    "# Loading in Shanties lyrics corpus\n",
    "shanties = open('../../../data/shanties_all.txt', encoding='utf-8').read()\n",
    "\n",
    "# Creating a list of all unique characters and variable of total number of uniques\n",
    "chars_list = sorted(list(set(shanties)))\n",
    "n_chars = len(chars_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-tUbc-2WALn1"
   },
   "outputs": [],
   "source": [
    "# Creating a dictionary to map each unique character to a number\n",
    "chars_to_ints = dict((c, i) for i, c in enumerate(chars_list))\n",
    "\n",
    "# Creating a dictionary to return numbers to characters\n",
    "ints_to_chars = dict((i, c) for  i, c in enumerate(chars_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Models\n",
    "Each model will be loaded from the model-building notebook and then loaded with the desired weights.\n",
    "\n",
    "Additionally each model will be added to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating empyt list for models\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 1\n",
    "shanty_writer1 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer1.load_weights('../model-building//model-weights/weights-improvement-01-2.3265.hdf5')\n",
    "models.append(shanty_writer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 2\n",
    "shanty_writer2 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer2.load_weights('../model-building//model-weights/weights-improvement-02-1.9675.hdf5')\n",
    "models.append(shanty_writer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 3\n",
    "shanty_writer3 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer3.load_weights('../model-building//model-weights/weights-improvement-03-1.8372.hdf5')\n",
    "models.append(shanty_writer3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 4\n",
    "shanty_writer4 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer4.load_weights('../model-building//model-weights/weights-improvement-04-1.7547.hdf5')\n",
    "models.append(shanty_writer4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 5\n",
    "shanty_writer5 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer5.load_weights('../model-building//model-weights/weights-improvement-05-1.6951.hdf5')\n",
    "models.append(shanty_writer5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 6\n",
    "shanty_writer6 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer6.load_weights('../model-building//model-weights/weights-improvement-06-1.6497.hdf5')\n",
    "models.append(shanty_writer6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 7\n",
    "shanty_writer7 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer7.load_weights('../model-building//model-weights/weights-improvement-07-1.6137.hdf5')\n",
    "models.append(shanty_writer7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 8\n",
    "shanty_writer8 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer8.load_weights('../model-building//model-weights/weights-improvement-08-1.5849.hdf5')\n",
    "models.append(shanty_writer8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 9\n",
    "shanty_writer9 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer9.load_weights('../model-building//model-weights/weights-improvement-09-1.5610.hdf5')\n",
    "models.append(shanty_writer9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 10\n",
    "shanty_writer10 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer10.load_weights('../model-building//model-weights/weights-improvement-10-1.5408.hdf5')\n",
    "models.append(shanty_writer10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 11\n",
    "shanty_writer11 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer11.load_weights('../model-building//model-weights/weights-improvement-11-1.5240.hdf5')\n",
    "models.append(shanty_writer11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 12\n",
    "shanty_writer12 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer12.load_weights('../model-building//model-weights/weights-improvement-12-1.5088.hdf5')\n",
    "models.append(shanty_writer12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 13\n",
    "shanty_writer13 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer13.load_weights('../model-building//model-weights/weights-improvement-13-1.4969.hdf5')\n",
    "models.append(shanty_writer13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 14\n",
    "shanty_writer14 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer14.load_weights('../model-building//model-weights/weights-improvement-14-1.4868.hdf5')\n",
    "models.append(shanty_writer14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 15\n",
    "shanty_writer15 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer15.load_weights('../model-building//model-weights/weights-improvement-15-1.4769.hdf5')\n",
    "models.append(shanty_writer15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 16\n",
    "shanty_writer16 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer16.load_weights('../model-building//model-weights/weights-improvement-16-1.4681.hdf5')\n",
    "models.append(shanty_writer16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 17\n",
    "shanty_writer17 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer17.load_weights('../model-building//model-weights/weights-improvement-17-1.4627.hdf5')\n",
    "models.append(shanty_writer17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 18\n",
    "shanty_writer18 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer18.load_weights('../model-building//model-weights/weights-improvement-18-1.4551.hdf5')\n",
    "models.append(shanty_writer18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 19\n",
    "shanty_writer19 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer19.load_weights('../model-building//model-weights/weights-improvement-19-1.4501.hdf5')\n",
    "models.append(shanty_writer19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Weights 20\n",
    "shanty_writer20 = load_model('../model-building/shanty_writer.h5')\n",
    "shanty_writer20.load_weights('../model-building//model-weights/weights-improvement-20-1.4466.hdf5')\n",
    "models.append(shanty_writer20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outputting Function\n",
    "For testing we'll use each model as a parameter in a function that will output the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lyrics_writer(seed_string, models_list, n_predictions):\n",
    "    count = 0\n",
    "    # Converting seed string into a list of numbers\n",
    "   # seq_pattern = [chars_to_ints[char] for char in seed_string.lower()]\n",
    "    for model in models_list:\n",
    "        # Adding one to counter\n",
    "        count += 1\n",
    "        # Converting seed string into a list of numbers\n",
    "        seq_pattern = [chars_to_ints[char] for char in seed_string.lower()]\n",
    "        # Creating empty string to append results too\n",
    "        output_string = ''\n",
    "        # Each iteration in loop will predict one character\n",
    "        for i in range(n_predictions):\n",
    "            # Creating x data to predict off. Reshaping and normalizing input list\n",
    "            x = np.reshape(seq_pattern, (1, len(seq_pattern), 1))\n",
    "            x = x / float(n_chars)\n",
    "            # Creating predictions\n",
    "            preds = model.predict(x, verbose=0)\n",
    "            # Ordering predictions by most likely character\n",
    "            index = np.argmax(preds)\n",
    "            # Converting result to character\n",
    "            result = ints_to_chars[index]\n",
    "            # Reading in current pattern\n",
    "            seq_in = [ints_to_chars[value] for value in seq_pattern]\n",
    "            # Adding result to input list\n",
    "            seq_pattern.append(index)\n",
    "            # Shifting pattern over one index for next pass through loop\n",
    "            seq_pattern = seq_pattern[1:len(seq_pattern)]\n",
    "            # Appending the result seed_string to print as final output\n",
    "            output_string = output_string + result\n",
    "            \n",
    "        print()\n",
    "        print(f'Epoch {count}:')\n",
    "        print(f'{seed_string}{output_string}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1:\n",
      "Washington DC is the best campus of General Assembn the sail the sailor sail the sailor sail the sailor sail the sailor sail the sailor sail the sailo\n",
      "\n",
      "\n",
      "Epoch 2:\n",
      "Washington DC is the best campus of General Assembe the sailor s bootier she s a sailor s bootier the sailor s bootier she s a sailor s bootier the sa\n",
      "\n",
      "\n",
      "Epoch 3:\n",
      "Washington DC is the best campus of General Assembe the sailor s io the sailor s io the sailor s io the sailor s io the sailor s io the sailor s io th\n",
      "\n",
      "\n",
      "Epoch 4:\n",
      "Washington DC is the best campus of General Assembe the ship was a sailor s a sailor s a sailor s a sailor s a sailor s a sailor s a sailor s a sailor\n",
      "\n",
      "\n",
      "Epoch 5:\n",
      "Washington DC is the best campus of General Assembe the sailor love we ll roar and the sailor love we ll roar and the sailor love we ll roar and the s\n",
      "\n",
      "\n",
      "Epoch 6:\n",
      "Washington DC is the best campus of General Assemb the sailor s land the sailor love the sailor s land the sailor love the sailor s land the sailor lo\n",
      "\n",
      "\n",
      "Epoch 7:\n",
      "Washington DC is the best campus of General Assembe the sea and the whnds and she s a lan o come all you bold sea bott and she s in the sea and the wh\n",
      "\n",
      "\n",
      "Epoch 8:\n",
      "Washington DC is the best campus of General Assembe the sailor lad i do adore and she said the sailor lad i do adore and she said the sailor lad i do \n",
      "\n",
      "\n",
      "Epoch 9:\n",
      "Washington DC is the best campus of General Assembe on the sea and the sailor s land and the sailor s love the sea and the sailor s land and the sailo\n",
      "\n",
      "\n",
      "Epoch 10:\n",
      "Washington DC is the best campus of General Assember the sea and the sea and the sea and the sea and the sea and the sea and the sea and the sea and t\n",
      "\n",
      "\n",
      "Epoch 11:\n",
      "Washington DC is the best campus of General Assember the sailor lad and the sailor lad and the sea so sail the sea so sail the sea so sail the sea so \n",
      "\n",
      "\n",
      "Epoch 12:\n",
      "Washington DC is the best campus of General Assember the sailor lad and the sailor lad and the sailor lad and the sailor lad and the sailor lad and th\n",
      "\n",
      "\n",
      "Epoch 13:\n",
      "Washington DC is the best campus of General Assember and the sailor loves the sailor loves the sailor loves the sailor loves the sailor loves the sail\n",
      "\n",
      "\n",
      "Epoch 14:\n",
      "Washington DC is the best campus of General Assember the sailor loves the maiden oh the boats of the boats and she sailed away the sailor loves the ma\n",
      "\n",
      "\n",
      "Epoch 15:\n",
      "Washington DC is the best campus of General Assember and the sea and the sailors when i was a sailor s land we ll sant and we ll roar like true you an\n",
      "\n",
      "\n",
      "Epoch 16:\n",
      "Washington DC is the best campus of General Assember the sailor loves the sailor loves the bottle oh the sailor loves the bottle oh the sailor loves t\n",
      "\n",
      "\n",
      "Epoch 17:\n",
      "Washington DC is the best campus of General Assember and the storm and the storm and the storm and the storm and the storm and the storm and the storm\n",
      "\n",
      "\n",
      "Epoch 18:\n",
      "Washington DC is the best campus of General Assember the sailor s streat and street and the sea and the sea and the sea and the sea and the sea and th\n",
      "\n",
      "\n",
      "Epoch 19:\n",
      "Washington DC is the best campus of General Assember and the ship s a cantain she s a health to the ship s a cantain she s a health to the ship s a ca\n",
      "\n",
      "\n",
      "Epoch 20:\n",
      "Washington DC is the best campus of General Assember the sailor loves the sea and the ship the sailor loves the sea and the ship the sailor loves the \n",
      "\n"
     ]
    }
   ],
   "source": [
    "lyrics_writer(input_string, models, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lyrics_writer(seed_string, model, n_predictions):\n",
    "    # Converting seed string into a list of numbers\n",
    "    seq_pattern = [chars_to_ints[char] for char in seed_string.lower()]\n",
    "    # Each iteration in loop will predict one character\n",
    "    for i in range(n_predictions):\n",
    "        # Creating x data to predict off. Reshaping and normalizing input list\n",
    "        x = np.reshape(seq_pattern, (1, len(seq_pattern), 1))\n",
    "        x = x / float(n_chars)\n",
    "        # Creating predictions\n",
    "        preds = model.predict(x, verbose=0)\n",
    "        # Ordering predictions by most likely character\n",
    "        index = np.argmax(preds)\n",
    "        # Converting result to character\n",
    "        result = ints_to_chars[index]\n",
    "        # Reading in current pattern\n",
    "        seq_in = [ints_to_chars[value] for value in seq_pattern]\n",
    "        # Adding result to input list\n",
    "        seq_pattern.append(index)\n",
    "        # Shifting pattern over one index for next pass through loop\n",
    "        seq_pattern = seq_pattern[1:len(seq_pattern)]\n",
    "        # Appending the result seed_string to print as final output\n",
    "        seed_string = seed_string + result\n",
    "        \n",
    "    print(seed_string)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Lyrics\n",
    "Each model weight will be tested with the same string. This string has to be the same number of characters as the sequence length that the model was trained on. In this case 50 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_string = 'Washington DC is the best campus of General Assemb'\n",
    "len(input_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Washington DC is the best campus of General Assembn the sail the sailor sail the sailor sail the sailor sail the sailor sail the sailor sail the sailor sail the sailor sail the sailor sail the sailor sail the sailor sail the sailor sail the sailor sa\n"
     ]
    }
   ],
   "source": [
    "# 1 Epoch Model\n",
    "lyrics_writer(input_string, shanty_writer01, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Washington DC is the best campus of General Assembe the sailor love we ll roar and the sailor love we ll roar and the sailor love we ll roar and the sailor love we ll roar and the sailor love we ll roar and the sailor love we ll roar and the sailor l\n"
     ]
    }
   ],
   "source": [
    "# 5 Epoch Model\n",
    "lyrics_writer(input_string, shanty_writer05, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Washington DC is the best campus of General Assember the sea and the sea and the sea and the sea and the sea and the sea and the sea and the sea and the sea and the sea and the sea and the sea and the sea and the sea and the sea and the sea and the s\n"
     ]
    }
   ],
   "source": [
    "# 10 Epoch Model\n",
    "lyrics_writer(input_string, shanty_writer10, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Washington DC is the best campus of General Assember and the sea and the sailors when i was a sailor s land we ll sant and we ll roar like true you and the sailors when i was a sailor s land we ll sant and we ll roar like true you and the sailors whe\n"
     ]
    }
   ],
   "source": [
    "# 15 Epoch Model\n",
    "lyrics_writer(input_string, shanty_writer15, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Washington DC is the best campus of General Assember the sailor loves the sea and the ship the sailor loves the sea and the ship the sailor loves the sea and the ship the sailor loves the sea and the ship the sailor loves the sea and the ship the sai\n"
     ]
    }
   ],
   "source": [
    "# 20 Epoch Model\n",
    "lyrics_writer(input_string, shanty_writer20, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "We can see several noticable things about the lyrics written:\n",
    "- Epoch 1 seems to have the least variety and coherence of the output\n",
    " - The first result is a \"n\" on the end of \"Assemb\"\n",
    "- Epoch 5\n",
    " - The model now has an \"e\" as the first result \n",
    " - \"we ll\" is most likely the output of \"we'll\"\n",
    "- Epoch 10 \n",
    " - \"Assemb\" has no become \"Assember\" which while nonsensical makes some innate lingustic sense\n",
    " - The rest of the results are a three word repeating pattern\n",
    "- Epoch 15\n",
    " - \"Assember\" remains\n",
    " - Here the repeating pattern is much longer and still semi coherent\n",
    "- Epoch 20\n",
    " - After 10 epochs it seems \"Assember\" is the decided way to finish the string \"Assemb\"\n",
    " - There is less variation then the 15 epoch model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "We see the model was almost too fit even after one epoch. In order to encourange more variability in the output \n",
    "\n",
    "change sequence length\n",
    "run a \"dumber\" model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Washington DC is the best campus of General Assemb\n",
      "[[2.82414202e-02 1.17880432e-02 6.29374385e-03 5.63297700e-03\n",
      "  4.10786225e-03 6.37205780e-01 1.13769830e-03 2.02101679e-03\n",
      "  3.20416950e-02 2.45767403e-02 1.40396311e-04 1.99400075e-02\n",
      "  5.29096089e-02 4.46747662e-03 8.36791936e-03 2.35760473e-02\n",
      "  1.77843636e-03 2.74043341e-05 1.65543202e-02 8.17929301e-03\n",
      "  1.13880560e-02 7.99876377e-02 1.21326644e-04 4.99726320e-03\n",
      "  5.05650678e-06 1.43193146e-02 1.93524946e-04]]\n",
      "5\n",
      "seq_in\n",
      "['w', 'a', 's', 'h', 'i', 'n', 'g', 't', 'o', 'n', ' ', 'd', 'c', ' ', 'i', 's', ' ', 't', 'h', 'e', ' ', 'b', 'e', 's', 't', ' ', 'c', 'a', 'm', 'p', 'u', 's', ' ', 'o', 'f', ' ', 'g', 'e', 'n', 'e', 'r', 'a', 'l', ' ', 'a', 's', 's', 'e', 'm', 'b']\n",
      "e[23, 1, 19, 8, 9, 14, 7, 20, 15, 14, 0, 4, 3, 0, 9, 19, 0, 20, 8, 5, 0, 2, 5, 19, 20, 0, 3, 1, 13, 16, 21, 19, 0, 15, 6, 0, 7, 5, 14, 5, 18, 1, 12, 0, 1, 19, 19, 5, 13, 2, 5]\n",
      "\n",
      "[1, 19, 8, 9, 14, 7, 20, 15, 14, 0, 4, 3, 0, 9, 19, 0, 20, 8, 5, 0, 2, 5, 19, 20, 0, 3, 1, 13, 16, 21, 19, 0, 15, 6, 0, 7, 5, 14, 5, 18, 1, 12, 0, 1, 19, 19, 5, 13, 2, 5]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Converting seed string into a list of numbers\n",
    "#input_list = [chars_to_ints[char] for char in seed_string.lower()]\n",
    "input_string = 'Washington DC is the best campus of General Assemb'\n",
    "\n",
    "input_list = [chars_to_ints[char] for char in input_string.lower()]\n",
    "\n",
    "pattern = input_list\n",
    "print (input_string)\n",
    "#print (f\"\\, {.join([int_to_char[value] for value in pattern])}, \\\")\n",
    "# generate characters\n",
    "for i in range(1):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_chars)\n",
    "    prediction = shanty_writer.predict(x, verbose=0)\n",
    "    #print(prediction)\n",
    "    index = np.argmax(prediction)\n",
    "   # print(index)\n",
    "    result = ints_to_chars[index]\n",
    "    seq_in = [ints_to_chars[value] for value in pattern]\n",
    "   # print('seq_in')\n",
    "   # print(seq_in)\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    #print(pattern)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "   # print()\n",
    "   # print(pattern)\n",
    "#print \"\\nDone.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "juRTFNlQALn7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of 50 character lenght patters: 698554\n"
     ]
    }
   ],
   "source": [
    "# Creating a list of patterns for the entire corpus\n",
    "seq_len = 50\n",
    "X_data = []\n",
    "y_data = []\n",
    "for i in range(0, len_shanties - seq_len, 1):\n",
    "    seq_in = shanties[i:i + seq_len]\n",
    "    seq_out = shanties[i + seq_len]\n",
    "    X_data.append([chars_to_ints[char] for char in seq_in])\n",
    "    y_data.append(chars_to_ints[seq_out])\n",
    "\n",
    "total_patterns = len(X_data)\n",
    "print(f'Total number of {seq_len} character length patters: {total_patterns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_string = 'My name is  my cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = [chars_to_ints[char] for char in input_string.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to format the inputed string to be 50 characters\n",
    "def string_format(string, n_char=50):\n",
    "    if len(string) < 50:\n",
    "        for i in range(50 -len(string)):\n",
    "            string = string + ' '\n",
    "    else:\n",
    "        string = string[:(n_char - len(string))]\n",
    "    input_list = [chars_to_ints[char] for char in string.lower()]\n",
    "    return string, input_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My name is  my cat'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(string_format(input_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input a string. Ch oooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo\n"
     ]
    }
   ],
   "source": [
    "# Asking user to input string to begin\n",
    "start_string = input('Input a string. Ch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_string, start_list = string_format(user_string)\n",
    "len(start_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Test Test Test Test Test Test Test Test Test \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_1_input to have shape (50, 1) but got array with shape (51, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-290-9442e2039f46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_chars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshanty_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mints_to_chars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1442\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected lstm_1_input to have shape (50, 1) but got array with shape (51, 1)"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "#start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = start_list\n",
    "print (start_string)\n",
    "#print (f\"\\, {.join([int_to_char[value] for value in pattern])}, \\\")\n",
    "# generate characters\n",
    "for i in range(100):\n",
    "\tx = np.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_chars)\n",
    "\tprediction = shanty_writer.predict(x, verbose=0)\n",
    "\tindex = np.argmax(prediction)\n",
    "\tresult = ints_to_chars[index]\n",
    "\tseq_in = [ints_to_chars[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "#print \"\\nDone.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test Test Test Test Test Test Test Test Test Test '"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_string = 'oooooooooooooooooooooooooooooooooooooooooooooooooo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = [chars_to_ints[char] for char in input_string.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oooooooooooooooooooooooooooooooooooooooooooooooooo\n",
      " the sea and the ship the sailor loves the sea and the ship the sailor loves the sea and the ship th"
     ]
    }
   ],
   "source": [
    "\n",
    "pattern = input_list\n",
    "print (input_string)\n",
    "#print (f\"\\, {.join([int_to_char[value] for value in pattern])}, \\\")\n",
    "# generate characters\n",
    "for i in range(100):\n",
    "\tx = np.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_chars)\n",
    "\tprediction = shanty_writer.predict(x, verbose=0)\n",
    "\tindex = np.argmax(prediction)\n",
    "\tresult = ints_to_chars[index]\n",
    "\tseq_in = [ints_to_chars[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "#print \"\\nDone.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oooooooooooooooooooooooooooooooooooooooooooooooooo\n",
      " the sail the sailor sail the sailor sail the sailor sail the sailor sail the sailor sail the sailor"
     ]
    }
   ],
   "source": [
    "\n",
    "pattern = input_list\n",
    "print (input_string)\n",
    "#print (f\"\\, {.join([int_to_char[value] for value in pattern])}, \\\")\n",
    "# generate characters\n",
    "for i in range(100):\n",
    "\tx = np.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_chars)\n",
    "\tprediction = shanty_writer01.predict(x, verbose=0)\n",
    "\tindex = np.argmax(prediction)\n",
    "\tresult = ints_to_chars[index]\n",
    "\tseq_in = [ints_to_chars[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "#print \"\\nDone.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi] *",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
