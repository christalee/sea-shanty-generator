{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "#from lxml import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting base url\n",
    "url = 'https://www.sailorsongs.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requesting links page\n",
    "res_links = requests.get(f'{url}lyrics.html')\n",
    "res_links.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting requests result into list of links\n",
    "links_soup = BeautifulSoup(res_links.content, 'lxml')\n",
    "links_list = links_soup.find_all('a', href=True)\n",
    "links_list = [x['href'] for x in links_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping non-song links from list\n",
    "del links_list[:7]\n",
    "del links_list[-6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty dictionary to hold songs\n",
    "shanties_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 a_cruising_we_will_go.html\n",
      "200 a_hundred_years_ago.html\n",
      "200 a_life_on_the_ocean_wave.html\n",
      "200 a_long_time_ago.html\n",
      "200 a_rollin_down_the_river.html\n",
      "200 a_rovin.html\n",
      "200 a_sailor_loves.html\n",
      "200 a_wet_sheet_and_a_flowing_sea.html\n",
      "200 abdul_abulbul_amir.html\n",
      "200 across_the_western_ocean.html\n",
      "200 admiral_benbow.html\n",
      "200 aha_me_boys_lukeys_boat.html\n",
      "200 alabama_john_cherokee.html\n",
      "200 all_for_me_grog.html\n",
      "200 anchors_aweigh_navy_song .html\n",
      "200 andrew_barton.html\n",
      "200 around_cape_horn.html\n",
      "200 asleep_in_the_deep.html\n",
      "200 away_rio.html\n",
      "200 aweigh_santy_ano.html\n",
      "200 the_ballad_of_captain_kidd.html\n",
      "200 the_balena.html\n",
      "200 baltimore_shanty.html\n",
      "200 banana_boat_song .html\n",
      "200 bang_lulu.html\n",
      "200 banks_of_the_brandywine.html\n",
      "200 the_banks_of_new_foundland.html\n",
      "200 the_banks_of_the_nile.html\n",
      "200 the_banks_of_the_sacramento.html\n",
      "200 the_banks_of_sweet_loch_ray.html\n",
      "200 the_bark_gay_head.html\n",
      "200 barnacle_bill_the_sailor.html\n",
      "200 battle_of_the_chesapeake_and_the_shannon.html\n",
      "200 bay_of_biscay.html\n",
      "200 bay_of_biscay_2.html\n",
      "200 bell_bottom_trousers.html\n",
      "200 ben_backstay.html\n",
      "200 the_bigler.html\n",
      "200 blackbird.html\n",
      "200 black_eyed_susan.html\n",
      "200 bold_dighton.html\n",
      "200 the_bold_princess_royal.html\n",
      "200 bold_riley.html\n",
      "200 boston_harbor.html\n",
      "200 botany_bay.html\n",
      "200 the_blackball_line.html\n",
      "200 blood_red_roses.html\n",
      "200 blow_bullies_blow.html\n",
      "200 blow_the_man_down.html\n",
      "200 blow_the_wind_westerly.html\n",
      "200 blow_ye_winds.html\n",
      "200 bobby_shaftoe.html\n",
      "200 bold_nelsons_praise.html\n",
      "200 the_bonny_ship_the_diamond.html\n",
      "200 boney.html\n",
      "200 british_man_o_war.html\n",
      "200 brother_noah.html\n",
      "200 bound_for_the_rio_grande.html\n",
      "200 bully_in_the_alley.html\n",
      "200 bye_bye_roseanna.html\n",
      "200 can_of_grog.html\n",
      "200 can_you_dance_the_polka_nygirls.html\n",
      "200 cape_cod_girls.html\n",
      "200 captain_kidd.html\n",
      "200 cest_laviron.html\n",
      "200 cheerly_man.html\n",
      "200 clear_the_track.html\n",
      "200 the_coast_of_high_barbaree.html\n",
      "200 cockles_and_mussels.html\n",
      "200 the_common_sailor.html\n",
      "200 the_constitution_and_the_guerriere.html\n",
      "200 crossing_the_bar.html\n",
      "200 the_cumberland_and_the_merrimack.html\n",
      "200 dance_to_your_daddy.html\n",
      "200 the_dark_eyed_sailor.html\n",
      "200 the_dead_horse.html\n",
      "200 derelict_redirect.html\n",
      "200 the_dogger_bank.html\n",
      "200 down_to_hilo.html\n",
      "200 the_dreadnaught.html\n",
      "200 drunken_sailor.html\n",
      "200 the_ebenezer.html\n",
      "200 the_edmund_fitzgerald.html\n",
      "200 eight_bells.html\n",
      "200 eliza_lee.html\n",
      "200 the_eriecanal.html\n",
      "200 the_essequibo_river.html\n",
      "200 farewell_to_grog.html\n",
      "200 the_faithful_sailor_boy.html\n",
      "200 the_female_smuggler.html\n",
      "200 fire_down_below.html\n",
      "200 fire_maringo.html\n",
      "200 the_fire_ship.html\n",
      "200 the_fish_of_the_sea.html\n",
      "200 the_flash_frigate.html\n",
      "200 the_flying_cloud.html\n",
      "200 the_gals_of_dublin_town.html\n",
      "200 general_taylor.html\n",
      "200 the_girl_i_left_behind_me.html\n",
      "200 the_glasgow.html\n",
      "200 go_to_sea_no_more.html\n",
      "200 the_golden_vanity.html\n",
      "200 the_good_ship_calibar.html\n",
      "200 the_good_ship_kangaroo.html\n",
      "200 good_bye_fare_you_well.html\n",
      "200 greenland_fishery .html\n",
      "200 the_grey_funnel_line.html\n",
      "200 the_handsome_cabin_boy.html\n",
      "200 hanging_johnny.html\n",
      "200 haul_away_joe.html\n",
      "200 haul_on_the_bowline.html\n",
      "200 heart_of_oak.html\n",
      "200 heave_away_me_johnnies.html\n",
      "200 henry_martin.html\n",
      "200 hilo_johnny_brown.html\n",
      "200 hieland_laddie.html\n",
      "200 high_barbaree.html\n",
      "200 hills_of_isle_of_haut.html\n",
      "200 hms_hood.html\n",
      "200 the_holy_ground.html\n",
      "200 homeward_bound.html\n",
      "200 houseboat_katie.html\n",
      "200 huckleberry_hunting.html\n",
      "200 i_am_a_brisk_and_sprightly_lad.html\n",
      "200 i_come_from_salem_city.html\n",
      "200 i_popped_out.html\n",
      "200 indian_lass.html\n",
      "200 in_heaven_there_is_no_beer.html\n",
      "200 irish_rover.html\n",
      "200 i_saw_three_ships.html\n",
      "200 its_of_a_sailor_bold.html\n",
      "200 jackaroe.html\n",
      "200 jack_the_sailor.html\n",
      "200 john_dory.html\n",
      "200 johnny_kanakanaka.html\n",
      "200 johnny_boker.html\n",
      "200 the_landlady_of_france.html\n",
      "200 the_lass_of_swansea_town.html\n",
      "200 leave_her_johnny_leave_her.html\n",
      "200 the_leaving_of_liverpool.html\n",
      "200 le_grand_coureur.html\n",
      "200 les_filles_de_la_rochelle.html\n",
      "200 let_the_bulgine_run.html\n",
      "200 lime_juice_ship.html\n",
      "200 lisbon.html\n",
      "200 london_julies.html\n",
      "200 the_low_low_lands_of_holland.html\n",
      "200 lowlands.html\n",
      "200 lustily.html\n",
      "200 maggie_may.html\n",
      "200 the_marines_hymn.html\n",
      "200 married_to_a_mermaid.html\n",
      "200 the_mermaid.html\n",
      "200 mingulay_boat_song.html\n",
      "200 my_boy_willie.html\n",
      "200 my_johnnie_is_a_shoemaker.html\n",
      "200 nancy_lee.html\n",
      "200 the_noblemans_daughter.html\n",
      "200 the_norfolk_girls.html\n",
      "200 o_columbia_the_gem_of_the_ocean.html\n",
      "200 old_stormalong.html\n",
      "200 on_the_old_fall_river_line.html\n",
      "200 one_of_the_roaming_kind.html\n",
      "200 only_one_more_day.html\n",
      "200 ox_eyed_man.html\n",
      "200 paddydoyles_boots.html\n",
      "200 paddy_get_back.html\n",
      "200 paddy_west.html\n",
      "404 paddy_works_on_the_railway\n",
      "200 pay_me_the_money_down.html\n",
      "200 the_pirate_song.html\n",
      "200 pleasant_and_delightful.html\n",
      "200 poor_joe_the_marine.html\n",
      "200 poor_old_horse.html\n",
      "200 proud_sally.html\n",
      "200 quare_bungle_rye .html\n",
      "200 queen_of_connemara.html\n",
      "200 randy_dandy_o.html\n",
      "200 ratcliffe_highway.html\n",
      "200 reuben_ranzo.html\n",
      "200 the_river_lea.html\n",
      "200 roast_beef_of_old_england.html\n",
      "200 rolling_down_to_old_maui.html\n",
      "200 roll_alabama_roll.html\n",
      "200 roll_the_cotton_down.html\n",
      "200 roll_the_old_chariot_along.html\n",
      "200 rolling_home.html\n",
      "200 the_roseabella.html\n",
      "200 round_the_bay_of_mexico.html\n",
      "200 round_the_corner.html\n",
      "200 sailing_sailing.html\n",
      "200 sailors_alphabet.html\n",
      "200 sailors_farewell_hymn.html\n",
      "200 sally_brown.html\n",
      "200 santa_ana_or_the_plains_of_mexico.html\n",
      "200 saturday_night_at_sea.html\n",
      "200 the_saucy_arethusa.html\n",
      "200 the_saucy_sailor_boy.html\n",
      "200 serafina.html\n",
      "200 the_sheffield_apprentice.html\n",
      "200 shenandoah.html\n",
      "200 the_ship_that_never_returned.html\n",
      "200 shoals_of_herring.html\n",
      "200 show_me_the_way_to_go_home.html\n",
      "200 sir_richard_grenvilles_farewell.html\n",
      "200 skye_boat_song.html\n",
      "200 sloop_john_b.html\n",
      "200 song_of_the_fishes.html\n",
      "200 south_australia.html\n",
      "404 spanish_ladies .html\n",
      "200 spanish_ladies_rogerchartier_version.html\n",
      "200 stand_to_your_guns.html\n",
      "200 stately_southerner.html\n",
      "200 stormy_weather_boys.html\n",
      "200 strike_the_bell.html\n",
      "200 tarpaulin_jacket.html\n",
      "200 ten_thousand_miles.html\n",
      "200 the_single_sailor.html\n",
      "200 the_token.html\n",
      "200 the_unfortunate_miss_bailey.html\n",
      "200 the_whalefishes.html\n",
      "200 bound_for_the_rio_grande.html\n",
      "200 three_score_and_ten.html\n",
      "200 tom_bowline.html\n",
      "200 tom_tough.html\n",
      "200 toms_gone_to_hilo.html\n",
      "200 top_man_and_the_afterguard.html\n",
      "200 van_diemens_land.html\n",
      "200 waltzing_matilda.html\n",
      "200 the_water_is_wide.html\n",
      "200 we_be_three_poor_mariners.html\n",
      "200 were_all_bound_to_go.html\n",
      "200 when_i_was_a_lad.html\n",
      "200 whiskey_for_my_johnny.html\n",
      "200 whiskey_for_my_johnny.html\n",
      "200 whiskey_in_the_jar.html\n",
      "200 whup_jamboree.html\n",
      "200 why_should_we_quarrel_for_riches.html\n",
      "200 will_watch.html\n",
      "200 wont_you_go_my_way.html\n",
      "200 yankee_john_stormalong.html\n",
      "200 yankee_man_o_war.html\n",
      "200 ye_mariners.html\n",
      "200 ye_parliament_of_england.html\n",
      "200 yo_ho_ho_and_a_bottle_of_rum.html\n",
      "200 young_monroe.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nCommenting out to see if cleaning all lyrics in one file is more efficient\\n    # Removing unwanted character strings\\n    lyrics = [x.replace(\"\\n\", \\'\\') for x in lyrics]\\n    lyrics = [x.replace(\"\\xa0\", \\'\\') for x in lyrics]\\n    lyrics = [x.replace(\"courtesy of www.SailorSongs.com\", \\' \\') for x in lyrics]\\n\\n    # Removing multiple spaces from lyrics\\n    lyrics = \\' \\'.join(lyrics)\\n    lyrics = \\' \\'.join(lyrics.split())\\n    \\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterating through\n",
    "for link in links_list:\n",
    "    # Requesting lyrics page\n",
    "    res_lyrics = requests.get(f'{url}{link}')\n",
    "    \n",
    "    # Putting in a small sleep to limit requests on server to under 100 per minutes\n",
    "    time.sleep(.75)\n",
    "    print(f'{res_lyrics.status_code} {link}')\n",
    "    \n",
    "    # Pulling song title\n",
    "    title = BeautifulSoup(res_lyrics.text).title.text\n",
    "\n",
    "    # Converting lyrics request into list\n",
    "    lyrics_soup = BeautifulSoup(res_lyrics.content, 'lxml')\n",
    "    lyrics_raw = lyrics_soup.find_all('p')\n",
    "    # Checking to see if lyrics block has intro text\n",
    "    if lyrics_raw[0].text.find('www.SailorSongs.com') != -1:\n",
    "        del lyrics_raw[0]\n",
    "    # Deleting non-lyrics from list\n",
    "    del lyrics_raw[-1]\n",
    "\n",
    "    # Converting soup into list\n",
    "    lyrics_raw = [x.text for x in lyrics_raw]\n",
    "    \n",
    "    # Converting list of strings to single string\n",
    "    lyrics = ''\n",
    "    lyrics = lyrics.join(lyrics_raw)\n",
    "    \n",
    "    # Updating Shanties Dict\n",
    "    shanties_dict.update({title : lyrics})\n",
    "'''\n",
    "Commenting out to see if cleaning all lyrics in one file is more efficient\n",
    "    # Removing unwanted character strings\n",
    "    lyrics = [x.replace(\"\\n\", '') for x in lyrics]\n",
    "    lyrics = [x.replace(\"\\xa0\", '') for x in lyrics]\n",
    "    lyrics = [x.replace(\"courtesy of www.SailorSongs.com\", ' ') for x in lyrics]\n",
    "\n",
    "    # Removing multiple spaces from lyrics\n",
    "    lyrics = ' '.join(lyrics)\n",
    "    lyrics = ' '.join(lyrics.split())\n",
    "    \n",
    "'''\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data frame for songs and lyrics\n",
    "sailor_songs_songs = pd.DataFrame(shanties_dict.items(), columns=['title', 'lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing to csv for use in other scripts\n",
    "sailor_songs_songs.to_csv('../data/sailor_songs_songs.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi] *",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
